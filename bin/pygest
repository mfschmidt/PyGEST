#!/usr/bin/env python3

""" pygest

    A command-line interface to the PyGEST library.

   commands:

        push : maximize the r-values between expression and a comparator matrix

            $ pygest push H03511009 L --minmax max
            $ pygest push H03511009 L --data /var/alt_data --samples cortical --approach exhaustive

        push : minimize the r-values between expression and a comparator matrix

            $ pygest push H03511009 L --minmax min

        order : order probes by their contribution to the r-value between expression and a comparator matrix

            $ pygest order H03511009 L --comparator dist

    options:

        --data /data       # could use any path with properly laid out expression data
        --comparator conn  # could also use dist
        --samples all      # could also use cortical
        --minmax max       # could also use min, up, down, +, -
        --cores 0          # 0 implies to use all but one; specify how many processes to spawn
        --algo smart       # could specify one, once, 1, smrt, every, evry, exhaustive
        --shuffle          # shuffle sample well_ids to generate null distribution
        --log              # override the log file to store output
        --verbose          # use flag for more verbose output to the console


"""

import os
import sys
import logging
import argparse
import socket
import datetime
import pkg_resources
import humanize
import numpy as np

# sys.path.insert(0, '/home/mike/projects/PyGEST')
from pygest.algorithms import algorithms

# Until this project is uploaded to pypi, we must manually put our path into the python path before import.
# Pull libs from dev source (this hacked path will go away once source is published and installed properly.)
# print("Including '{}' in python libraries for access to pygest.".format(
#     os.path.dirname(os.path.dirname(__file__))
# ))
# include_path = os.path.dirname(os.path.dirname(__file__))
# sys.path.insert(0, include_path)
import pygest as ge

# PyGEST likes to manage its own threads since it knows how it's distributing them.
if 'OPENBLAS_NUM_THREADS' not in os.environ:
    os.environ['OPENBLAS_NUM_THREADS'] = '1'


def parse_args():
    """

    :return: a parser object and an args object
    """
    # Allow the caller to specify a donor (or other AHBGE-supported sample filter)
    if '--version' in sys.argv:
        print(pkg_resources.require("pygest")[0].version)
        sys.exit(0)

    parser = argparse.ArgumentParser(description="""
    PyGEST client
    
    usage:
    
        pygest command donor hemisphere samples [options]
    
    example:
    
        pygest pushr 1009 L cortex
    
    The preceding command will repeatedly remove genes to achieve the highest possible
    correlation between expression similarity and connectivity for donor H03511009's
    left hemisphere cortical samples.
    
    Available commands:
    
        pushr    : whack-a-probe repeatedly to push Mantel correlations to their limits.
                   combine with --minmax (-m) to push up or down
        order    : One time, order the probes by their contribution to the Mantel correlation.
        dryrun   : Checks for existence of data, and reports arguments/defaults.
        overview : 
        
    """)
    parser.add_argument("command",
                        help="What can PyGEST do for you?")
    parser.add_argument("donor", default="all", nargs='?',
                        help="Which ABI donor would you like to include?")
    parser.add_argument("hemisphere", default="all", nargs='?',
                        help="Which hemisphere would you like to include?")
    parser.add_argument("samples", default="all", nargs='?',
                        help="A subset of samples (well_ids) to include")
    parser.add_argument("-c", "--comparator", dest="comparator", default="conn",
                        help="What are we comparing expression against? 'conn' or 'cons' or 'dist'")
    parser.add_argument("-m", "--minmax", dest="direction", default="max",
                        help="What direction to push the correlations? 'max' or 'min'?")
    parser.add_argument("-d", "--data", dest="data", nargs='?', type=str, default='NONE',
                        help="Where are the BIDS and cache directories?")
    parser.add_argument("-v", "--verbose", dest="verbose", action='store_true', default=False,
                        help="Turn on output of debug information.")
    parser.add_argument("-n", "--n_cpu", "--cores", dest="cores", default="0", type=int,
                        help="How many cores should we use? 0 means to use {n_cpus} - 1")
    parser.add_argument("--algo", dest="algorithm", default="smrt",
                        help="How aggressive should we be in finding max/min? 'once', 'smrt', 'evry'")
    parser.add_argument("--masks", dest="masks", default=[], nargs='+',
                        help="What should we mask out to remove proximity effect? 'none', 'fine', 'coarse', '#'")
    parser.add_argument("--adj", dest="adjust", default="none",
                        help="How should we correct for proximity? 'none', 'linear', 'log'")
    parser.add_argument("--shuffle", dest="shuffle", action='store_true', default=False,
                        help="Shuffle sample well_ids to generate null distribution.")
    parser.add_argument("--version", dest="version", action='store_true', default=False,
                        help="Report the version and exit.")
    parser.add_argument("--seed", dest="seed", type=int, default=0,
                        help="Provide a seed for randomizing the expression data shuffle.")
    parser.add_argument("--log", dest="log", default='',
                        help="Provide a path to a log file to save output.")
    args = parser.parse_args()

    # Translate, interpret, and derive some of the arguments non-literally
    args.donor = ge.donor_name(args.donor)

    if args.data == "NONE":
        if "PYGEST_DATA" in os.environ:
            args.data = os.environ['PYGEST_DATA']
        else:
            print("I don't know where to find data. Try one of the following, with your own path:")
            print("")
            print("    $ pygest {} --data /home/mike/ge_data".format(" ".join(sys.argv[1:])))
            print("")
            print("or, even better, set it in your environment (use ~/.bashrc as a permanent solution)")
            print("")
            print("    $ export PYGEST_DATA=/home/mike/ge_data")
            print("    $ pygest {}".format(" ".join(sys.argv[1:])))
            print("")
            sys.exit(1)

    if args.command.lower() in ['push_up', 'push_max', 'push_hi', 'push_high']:
        args.direction = 'max'
        args.command = 'push'
    elif args.command.lower() in ['push_down', 'push_min', 'push_lo', 'push_low']:
        args.direction = 'min'
        args.command = 'push'

    if args.direction.lower() in ['min', 'down', '-', ]:
        args.direction = 'min'
        args.going_up = False
        args.going_down = True
    else:
        args.direction = 'max'
        args.going_up = True
        args.going_down = False

    # Standardize to a single value to avoid mis-spellings f'ing us later
    if args.algorithm in algorithms:
        args.algorithm = algorithms[args.algorithm]
    else:
        args.algorithm = algorithms['smrt']

    args.samples = args.samples[:3]

    if args.command == "dryrun":
        args.verbose = True

    args.beginning = datetime.datetime.now()
    return parser, args


def setup(args):
    """ Create a logger and handlers, and use them while gaining access to ge.Data.

    :param args: command-line arguments
    :return: PyGEST::ExpressionData object, logger
    """

    # Set up logging, formatted with datetimes.
    log_formatter = logging.Formatter(fmt='%(asctime)s | %(message)s', datefmt='%Y-%m-%d_%H:%M:%S')
    logger = logging.getLogger('pygest')
    logger.setLevel(1)

    # Set up the console (stdout) log handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(log_formatter)
    console_handler.setLevel(logging.DEBUG if args.verbose else logging.INFO)
    logger.addHandler(console_handler)

    # Set up the file handler, if requested
    if args.command != "dryrun":
        if args.log == '':
            file_handler = logging.FileHandler(
                set_name(args) + '.log',
                mode='a'
            )
            file_handler.setFormatter(log_formatter)
            file_handler.setLevel(logging.DEBUG)
            logger.addHandler(file_handler)
        else:
            file_handler = logging.FileHandler(args.log, mode='a+')
            file_handler.setFormatter(log_formatter)
            # file_handler.setLevel(logging.DEBUG if args.verbose else logging.INFO)
            # As a design decision, heavy logging to a file is almost always desirable, without clogging stdout
            file_handler.setLevel(logging.DEBUG)
            logger.addHandler(file_handler)

    data = ge.Data(args.data, logger)

    return data, logger


# Define some functions to wrap different commands
def set_name(args):
    """ Standardize the way filenames are generated for this particular set of data.
    :param args: command-line arguments
    """
    if len(args.masks) == 0:
        mask_string = 'none'
    else:
        mask_string = '+'.join(args.masks)

    if args.shuffle:
        top_dir = os.path.join(args.data, 'shuffles')
    else:
        top_dir = os.path.join(args.data, 'derivatives')

    set_dir = '_'.join([
        '-'.join(['sub', ge.donor_name(args.donor)]),
        '-'.join(['hem', args.hemisphere]),
        '-'.join(['ctx', args.samples]),
    ])
    alg_dir = '_'.join([
        '-'.join(['tgt', args.direction]),
        '-'.join(['alg', args.algorithm]),
    ])
    file_name = '_'.join([
        '-'.join(['sub', ge.donor_name(args.donor)]),
        '-'.join(['cmp', args.comparator[:4]]),
        '-'.join(['msk', mask_string]),
        '-'.join(['adj', args.adjust]),
    ])
    if args.donor == 'test':
        file_name = '_'.join(['dt-' + args.beginning.strftime("%Y%m%d%H%M%S"), file_name])

    # Building reports and generating data require different levels of name
    if args.command == 'overview':
        new_name = os.path.join(top_dir, set_dir)
    else:
        new_name = os.path.join(top_dir, set_dir, alg_dir, file_name)

    if args.command == 'order':
        new_name = '_'.join([new_name, 'order'])
    if args.shuffle:
        new_name = '_'.join([new_name, 'seed-{0:04d}'.format(args.seed)])

    os.makedirs(os.path.dirname(os.path.abspath(new_name)), exist_ok=True)

    return new_name


def write_sidecar(base_name, start_time):
    """ Write a json file to accompany other files using base_name

    :param base_name: The full path, sans extension, of other related files
    :param start_time: the datetime to report as the time this process began
    """

    end_time = datetime.datetime.now()

    with open(base_name + '.json', 'a+') as f:
        f.write("{\n")
        f.write("    \"host\": \"{}\",\n".format(socket.gethostname()))
        f.write("    \"command\": \"{}\",\n".format(" ".join(sys.argv[:])))
        f.write("    \"blas\": \"{} thread{}\",\n".format(
            os.environ['OPENBLAS_NUM_THREADS'],
            '' if int(os.environ['OPENBLAS_NUM_THREADS']) == 1 else 's'
        ))
        f.write("    \"pygest version\": \"{}\",\n".format(pkg_resources.require("pygest")[0].version))
        f.write("    \"log\": \"{}\",\n".format(base_name + '.log'))
        f.write("    \"data\": \"{}\",\n".format(base_name + '.tsv'))
        f.write("    \"began\": \"{}\",\n".format(start_time.strftime("%Y-%m-%d %H:%M:%S")))
        f.write("    \"completed\": \"{}\",\n".format(end_time.strftime("%Y-%m-%d %H:%M:%S")))
        f.write("    \"elapsed\": \"{}\",\n".format(end_time - start_time))
        f.write("    \"duration\": \"{}\",\n".format(humanize.naturaldelta(end_time - start_time)))
        f.write("}\n")


def one_mask(data, df, mask_type):
    """ return a vector of booleans from the lower triangle of a matching-matrix based on 'mask_type'

    :param data: pygest.Expression data object to access samples and distances
    :param df: pandas.DataFrame with samples as columns
    :param str mask_type: A list of strings to specify matching masks, or a minimum distance to mask out
    :return: A boolean vector to remove unwanted items from any sample x sample triangle vector
    """

    # If mask is a number, use it as a distance filter
    try:
        min_dist = float(mask_type)
        mask_vector = np.array(data.distance_vector(df.columns) > min_dist, dtype=bool)
        print("        masking out {} of {} edges closer than {}mm apart.".format(
            sum(~mask_vector), len(mask_vector), min_dist
        ))
        return mask_vector
    except TypeError:
        pass
    except ValueError:
        pass

    # Mask is not a number, so treat it as a matching filter
    if mask_type[:4] == 'fine':
        items = data.samples(samples=df.columns)['fine_name']
    elif mask_type[:6] == 'coarse':
        items = data.samples(samples=df.columns)['coarse_name']
    else:
        items = data.samples(samples=df.columns)['structure_name']
    mask_array = np.ndarray((len(items), len(items)), dtype=bool)

    # There is, potentially, a nice vectorized way to do this, but I can't find it.
    # So, looping works and is easy to read, although it might cost us a few extra ms.
    for i, y in enumerate(items):
        for j, x in enumerate(items):
            # Generate one edge of the match matrix
            mask_array[i][j] = True if mask_type == 'none' else (x != y)
    mask_vector = mask_array[np.tril_indices(n=mask_array.shape[0], k=-1)]

    print("        masking out {} of {} '{}' edges.".format(
        sum(~mask_vector), len(mask_vector), mask_type
    ))
    return mask_vector


def cum_mask(data, df, mask_types):
    """ return a cumulate vector of booleans from the lower triangle of each mask specified in mask_types

    :param data: pygest.Expression data object to access samples and distances
    :param df: pandas.DataFrame with samples as columns
    :param str mask_types: A list of strings to specify matching masks, or a minimum distance to mask out
    :return: A boolean vector to remove unwanted items from any sample x sample triangle vector
    """

    # Generate a mask of all True values. We can then use it as-is or 'logical and' it with others.
    full_mask = one_mask(data, df, 'none')
    if mask_types == [] or mask_types == ['none']:
        return full_mask

    for mask_type in mask_types:
        full_mask = full_mask & one_mask(data, df, mask_type)

    # The resulting mask should be a logical and mask of all masks in mask_types
    return full_mask


def push(data, args, logger):
    """ Figure out the most influential genes by whacking them cumulatively.

        The pandas DataFrame object is pickled to /{data}/results/maxes/{name}.df

    :param data: pygest.ExpressionData object for data access
    :param args: Command line arguments from shell
    :param logging.Logger logger: logger object, if desired
    """

    # Pull data
    exp = get_expression(data, args, logger)
    cmp = get_comparator(data, args.comparator, args.donor, exp.columns, logger)
    dst = get_comparator(data, 'dist', args.donor, exp.columns, logger)

    # Should we null the distribution first?
    if args.shuffle:
        exp = ge.algorithms.shuffled(exp, cols=True, seed=args.seed)

    # Figure out our temporary and final file names
    base_path = set_name(args)

    # If we've already done this, don't waste the time.
    if os.path.exists(base_path + '.tsv'):
        logger.info("{} already exists in {}. no need to {}imize the same correlations again.".format(
            os.path.basename(base_path + '.tsv'), os.path.abspath(base_path), args.direction
        ))
    else:
        logger.info("Removing probes to {}imize correlation.".format(args.direction))
        v_mask = cum_mask(data, exp, args.masks)
        gene_df = ge.algorithms.push_score(
            exp, cmp, dst, algo=args.algorithm, ascending=args.going_up, mask=v_mask, adjust=args.adjust,
            progress_file=base_path + '.partial.df', cores=args.cores, logger=logger
        )
        logger.info("Saving r-{}imization over gene removal to {}.".format(
            args.direction, base_path + '.tsv'
        ))
        gene_df.sort_index(ascending=False).to_csv(
            base_path + '.tsv', sep='\t', na_rep="n/a", float_format="%0.20f"
        )
        # The complete list is now written to tsv; get rid of the temporary cached list.
        os.remove(base_path + '.partial.df',)

        write_sidecar(base_path, args.beginning)


def order(data, args, logger):
    """ Figure out the most influential genes by whacking each only once.

        The pandas DataFrame object is pickled to /{data}/results/{name}.df

    :param data: Comparator (typically connectivity or distance) DataFrame
    :param args: Command line arguments from shell
    :param logging.Logger logger: logger object, if desired
    """

    exp = get_expression(data, args, logger)
    cmp = get_comparator(data, args.comparator, args.donor, exp.columns, logger)
    dst = get_comparator(data, 'dist', args.donor, exp.columns, logger)

    base_path = set_name(args)

    # Order probes once
    v_mask = cum_mask(data, exp, args.masks)
    probe_order = ge.algorithms.reorder_probes(
        exp, cmp, dst,
        ascending=args.going_up, procs=args.cores, mask=v_mask, adjust=args.adjust,
        include_full=True, logger=logger
    )
    logger.info("Saving probe order to {}.".format(base_path + '.tsv'))
    probe_order.sort_values(by=['delta'], ascending=args.going_up).to_csv(
        base_path + '.tsv', sep='\t', na_rep="n/a", float_format="%0.20f"
    )

    # And leave some notes about the process
    write_sidecar(base_path, args.beginning)


def overview(data, args, logger):
    """ Save a pdf with multiple plots describing the exp and cmp data.

    :param pygest.ExpressionData data: PyGEST ExpressionData instance, already initialized
    :param args: Command line arguments from shell
    :param logging.Logger logger: logger object, if desired
    """

    base_path = set_name(args)
    the_sample = "_".join([ge.donor_name(args.donor), args.hemisphere, args.samples])
    report_path = base_path.replace('derivatives', 'reports')
    # image_path = os.path.join(report_path, 'images')

    report_file = os.path.join(report_path, the_sample + '_overview.pdf')

    logger.info("Building an overview report for {} in {}".format(the_sample, report_path))

    report_file = ge.reporting.sample_overview(data, args, report_file, logger=logger)

    logger.info("See {} for completed report.".format(report_file))


def log_status(data, args, logger):
    """ Disclose the status of sourcedata and derivatives to the logger.

    :param pygest.ExpressionData data: PyGEST ExpressionData instance, already initialized
    :param args: Command line arguments from shell
    :param logging.Logger logger: logger object, if desired
    """

    if logger is None:
        logger = logging.getLogger('pygest')

    logger.info("SOURCES:")
    data.log_status(regarding=args.donor)
    logger.info("RESULTS:")
    ge.reporting.log_status(data, args.data, regarding=args.donor, logger=logger)


def report_context(args, logger):
    """ Get started by dumping our context.
    """
    # print("Trying to report context to logger at level {}".format(logger.level))
    # for handler in logger.handlers:
    #     print("  logger {} has handler {} at level {}".format(logger.name, handler.name, handler.level))
    logger.info("--------------------------------------------------------------------------------")
    logger.info("  Command: {}".format(" ".join(sys.argv[:])))
    logger.info("  OPENBLAS_NUM_THREADS = {}".format(os.environ['OPENBLAS_NUM_THREADS']))
    logger.info("  PyGEST is running version {}".format(pkg_resources.require("pygest")[0].version))
    logger.debug("    interpretation of arguments:")
    for k in args.__dict__:
        if args.__dict__[k] is not None:
            logger.debug("      - {} = {}".format(k, args.__dict__[k]))
    logger.info("    name string for files:")
    logger.info("    '{}'".format(set_name(args)))
    logger.info("--------------------------------------------------------------------------------")


def get_expression(data, args, logger):
    """ Gather expression data.
    """
    logger.info("Gathering expression data for {}.".format(args.donor))
    if args.donor == 'test':
        expr = data.expression(probes='test', samples='test')
    else:
        expr = data.expression(
            probes='richiardi',
            samples=data.samples(donor=args.donor, hemisphere=args.hemisphere)
        )
    logger.info("    retrieved [{}-probe X {}-sample] DataFrame.".format(
        len(expr.index), len(expr.columns)
    ))
    # Cache a list of richiardi samples; we need to filter both IN and OUT of this list
    richiardi_samples = list(data.samples('richiardi').index)
    len_before = len(expr.columns)
    if args.samples == 'cor':
        cort_samples = [well_id for well_id in expr.columns if well_id in richiardi_samples]
        expr = expr[cort_samples]
    elif args.samples == 'sub':
        subc_samples = [well_id for well_id in expr.columns if well_id not in richiardi_samples]
        expr = expr[subc_samples]
    logger.info("    {}-only data requested, keeping {} of the original {} samples.".format(
        args.samples, len(expr.columns), len_before
    ))
    return expr


def get_comparator(data, name, donor, sample_filter, logger):
    """ Gather comparison data
    """
    if name[:4].lower() == 'conn':
        logger.info("Gathering {} connectivity data for {}.".format('INDI', donor))
        # We should have a square connectivity matrix from INDI, 2551 x 2551
        comp = data.connectivity('indi', samples=sample_filter)
        logger.info("    using [{} X {}] connectivity matrix.".format(len(comp.index), len(comp.columns)))
    elif name[:4].lower() == 'cons':
        logger.info("Gathering {} connectivity similarity data for {}.".format('INDI', donor))
        # We should have a square connectivity matrix from INDI, 2551 x 2551
        comp = data.connectivity_similarity('indi', samples=sample_filter)
        logger.info("    using [{} X {}] connectivity similarity matrix.".format(
            len(comp.index), len(comp.columns)
        ))
    elif name[:4].lower() == 'dist':
        logger.info("Gathering distance data for {}.".format(donor))
        # We need to generate a square distance matrix from selected samples
        comp = data.distance_dataframe(sample_filter)
        logger.info("    using [{} X {}] distance matrix.".format(comp.shape[0], comp.shape[1]))
    else:
        logger.warning("Expression can be assessed vs connectivity or distance.")
        logger.warning("I don't understand '{}', and cannot continue.".format(name))
        sys.exit()
    return comp


def main():
    # Handle the many command-line arguments
    parser, arguments = parse_args()

    # For short, simple commands, just run and done
    if arguments.command == "version":
        print("pygest v{}".format(pkg_resources.require("pygest")[0].version))
        sys.exit(0)

    # Instantiate and configure pygest
    data, logger = setup(arguments)

    report_context(arguments, logger)

    # Execute the specified task
    if arguments.command.lower() == 'push':
        push(data, arguments, logger)
    elif arguments.command.lower() == 'order':
        order(data, arguments, logger)
    elif arguments.command.lower() == 'dryrun':
        logger.info("{} {}".format(arguments.data, 'exists' if os.path.isdir(arguments.data) else 'is not a directory'))
    elif arguments.command.lower() == 'overview':
        overview(data, arguments, logger)
    elif arguments.command.lower() == 'status':
        log_status(data, arguments, logger)
    else:
        print("I don't recognize the command, '{}'".format(arguments.command))

    logger.info("Done")


if __name__ == '__main__':
    main()
