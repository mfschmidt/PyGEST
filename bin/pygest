#!/usr/bin/env python3

""" pygest

    A command-line interface to the PyGEST library.

   commands:

        maxr : maximize the r-values between expression and a comparator matrix

            $ pygest maxr H03511009 L
            $ pygest maxr H03511009 L --ge_dir /var/alt_data --samples cortical --approach exhaustive

        minr : minimize the r-values between expression and a comparator matrix

            $ pygest minr H03511009 L

            same as

            $ pygest maxr H03511009 L --direction min

        order : order probes by their contribution to the r-value between expression and a comparator matrix

            $ pygest order H03511009 L --comparator dist

        null : create null distribution of maximized gene list for comparison with real data

            $ pygest null H03511009 L --seed 42

    options:

        --ge_dir /data     # could use any path with properly laid out expression data
        --comparator conn  # could also use dist
        --samples all      # could also use cortical
        --direction max    # could also use min
        --cores 0          # 0 implies to use all but one; specify how many processes to spawn
        --approach smart   # could specify one or exhaustive
        --log              # specify a log file to store output
        --verbose          # use flag for more verbose output


"""

import os
import sys
import logging
import argparse
import pickle
import numpy as np

# Until this project is uploaded to pypi, we must manually put our path into the python path before import.
# Pull libs from dev source
#     (this hacked path will go away once source is published and installed properly.)
include_path = os.path.dirname(os.path.dirname(__file__))
sys.path.insert(0, include_path)
import pygest as ge

# PyGEST likes to manage its own threads since it knows how it's distributing them.
if 'OPENBLAS_NUM_THREADS' not in os.environ:
    os.environ['OPENBLAS_NUM_THREADS'] = '1'


def parse_args():
    # Allow the caller to specify a donor (or other AHBGE-supported sample filter)
    parser = argparse.ArgumentParser(description='PyGEST client')
    parser.add_argument("command", help="What can PyGEST do for you?")
    parser.add_argument("donor", default="all", nargs='?',
                        help="Which ABI donor would you like to include?")
    parser.add_argument("hemisphere", default="all", nargs='?',
                        help="Which hemisphere would you like to include?")
    parser.add_argument("--samples", dest="samples", default="all",
                        help="A subset of samples (well_ids) to include")
    parser.add_argument("--comparator", dest="comparator", default="conn",
                        help="What are we comparing expression against? 'conn' or 'dist'")
    parser.add_argument("--ge_dir", dest="ge_dir", nargs='?', type=str, default='/data',
                        help="Where are the BIDS and cache directories?")
    parser.add_argument("--verbose", "-v", dest="verbose", action='store_true', default=False,
                        help="Turn on output of debug information.")
    parser.add_argument("--direction", dest="direction", default="up",
                        help="Should we maximize toward +1.0, or minimize toward -1.0?")
    parser.add_argument("--cores", dest="cores", default="0", type=int,
                        help="How many cores should we use? 0 means to use {n_cpus} - 1")
    parser.add_argument("--approach", dest="approach", default="smart",
                        help="How aggressive should we be in finding max/min? 'one', 'smart', 'exhaustive'")
    parser.add_argument("--seed", dest="seed", type=int, default=0,
                        help="Provide a seed for randomizing the expression data shuffle.")
    parser.add_argument("--log", dest="log", default='',
                        help="Provide a path to a log file to save output.")
    args = parser.parse_args()

    args.going_up = args.direction.lower() in ['up', 'max', 'pos']
    args.direction = 'max' if args.going_up else 'min'
    if args.donor in ge.donor_map:
        args.donor = ge.donor_map[args.donor]

    return args


def configure_logging(args):
    # Set up logging, formatted with datetimes.
    log_formatter = logging.Formatter(fmt='%(asctime)s | %(message)s', datefmt='%Y-%m-%d_%H:%M:%S')
    logger = logging.getLogger('pygest')
    logger.setLevel(1)

    # Set up the console (stdout) log handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(log_formatter)
    console_handler.setLevel(logging.DEBUG if args.verbose else logging.INFO)
    logger.addHandler(console_handler)

    # Set up the file handler, if requested
    if args.log != '':
        file_handler = logging.FileHandler(args.log)
        file_handler.setFormatter(log_formatter)
        file_handler.setLevel(logging.DEBUG if args.verbose else logging.INFO)
        logger.addHandler(file_handler)

    return logger


# Define some functions to wrap different commands
def set_name(args):
    """ Standardize the way filenames are generated for this particular set of data.
    """
    new_name = '_'.join([
        args.donor,
        args.hemisphere,
        args.samples[:3],
        args.comparator[:4],
        args.direction,
    ])
    if args.command.lower() == 'make_null':
        new_name = '_'.join([new_name, 'NULL-{0:03d}'.format(args.seed)])
    return new_name


def max_r(exp, cmp, args, logger):
    """ Figure out the most influential genes by whacking them cumulatively.

        The pandas DataFrame object is pickled to /{data}/results/maxes/{name}.df

    :param pandas.DataFrame exp: Expression DataFrame
    :param pandas.DataFrame cmp: Comparator (typically connectivity or distance) DataFrame
    :param args: Command line arguments from shell
    :param logging.Logger logger: logger object, if desired
    """

    # Figure out our temporary and final filenames
    progress_filename = '_'.join(['partial', set_name(args), '.df'])
    final_filename = args.direction + '-by-' + args.approach[:3] + '_' + set_name(args) + '.df'

    # If we've already done this, don't waste the time.
    if os.path.exists(os.path.join(args.ge_dir, 'results', 'maxes', final_filename)):
        logger.info("{} already exists in {}. no need to {}imize the same correlations again.".format(
            final_filename, os.path.join(args.ge_dir, 'results', 'maxes'), args.direction
        ))
    else:
        logger.info("Removing probes to {}imize correlation.".format(args.direction))
        gene_df = ge.algorithms.maximize_correlation(
            exp, cmp, method=args.approach, ascending=args.going_up,
            progress_file=os.path.join(args.ge_dir, 'cache', 'maxes', progress_filename),
            cores=args.cores, logger=logger
        )
        logger.info("Saving r-{}imization over gene removal to {}.".format(
            args.direction, final_filename
        ))
        with open(os.path.join(args.ge_dir, 'results', 'maxes', final_filename), 'wb') as handle:
            pickle.dump(gene_df, handle, protocol=pickle.HIGHEST_PROTOCOL)
        # The complete list is written; get rid of the temporary cached list.
        os.remove(os.path.join(args.ge_dir, 'cache', 'maxes', progress_filename))


def order(exp, cmp, args, logger):
    """ Figure out the most influential genes by whacking each only once.

        The pandas DataFrame object is pickled to /{data}/results/{name}.df

    :param pandas.DataFrame exp: Expression DataFrame
    :param pandas.DataFrame cmp: Comparator (typically connectivity or distance) DataFrame
    :param args: Command line arguments from shell
    :param logging.Logger logger: logger object, if desired
    """
    probe_order = ge.algorithms.order_probes_by_r(
        exp, cmp, ascending=args.going_up, procs=args.cores, include_full=True, logger=logger
    )
    filename = 'order' + '_' + set_name(args) + '.df'
    logger.info("Saving probe order to {}.".format(filename))
    with open(os.path.join(args.ge_dir, 'results', filename), 'wb') as handle:
        pickle.dump(probe_order, handle, protocol=pickle.HIGHEST_PROTOCOL)


def make_null_dist(exp, cmp, args, logger):
    """ Shuffle gene expression values, then maximize the r. For null hypothesis comparison to real max_r.
    """
    null_expr = ge.algorithms.shuffled(exp, cols=True, seed=args.seed)
    max_r(null_expr, cmp, args, logger)


def report_context(args, logger):
    """ Get started by dumping our context.
    """
    # print("Trying to report context to logger at level {}".format(logger.level))
    # for handler in logger.handlers:
    #     print("  logger {} has handler {} at level {}".format(logger.name, handler.name, handler.level))
    logger.info("--------------------------------------------------------------------------------")
    logger.info("  Command: {}".format(" ".join(sys.argv[:])))
    logger.info("  OPENBLAS_NUM_THREADS = {}".format(os.environ['OPENBLAS_NUM_THREADS']))
    if args.verbose:
        logger.info("    interpretation of arguments:")
        for k in args.__dict__:
            if args.__dict__[k] is not None:
                logger.info("      - {} = {}".format(k, args.__dict__[k]))
        logger.info("    name string for files is '{}'".format(set_name(args)))
    logger.info("--------------------------------------------------------------------------------")


def get_expression(data, args, logger):
    """ Gather expression data.
    """
    logger.info("Gathering expression data for {}.".format(args.donor))
    if args.donor == 'test':
        expr = data.expression(probes='test', samples='test')
    else:
        expr = data.expression(
            probes='richiardi',
            samples=data.samples(donor=args.donor, hemisphere=args.hemisphere)
        )
    logger.info("    retrieved [{}-probe X {}-sample] DataFrame.".format(
        len(expr.index), len(expr.columns)
    ))
    if args.samples[:4] == 'cort':
        len_before = len(expr.columns)
        cort_samples = [well_id for well_id in data.samples('richiardi').index if well_id in expr.columns]
        expr = expr[cort_samples]
        logger.info("    cortical-only data requested, keeping {} of the original {} samples.".format(
            len(expr.columns), len_before
        ))
    return expr


def get_comparator(data, args, sample_filter, logger):
    """ Gather comparison data
    """
    if args.comparator[:4].lower() == 'conn':
        logger.info("Gathering {} connectivity data for {}.".format('INDI', args.donor))
        # We should have a square connectivity matrix from INDI, 2551 x 2551
        comp = data.connectivity('indi', samples=sample_filter)
        logger.info("    using [{} X {}] connectivity matrix.".format(len(comp.index), len(comp.columns)))
    elif args.comparator[:4].lower() == 'dist':
        logger.info("Gathering distance data for {}.".format(args.donor))
        # We need to generate a square distance matrix from selected samples
        comp = data.distance_dataframe(sample_filter)
        logger.info("    using [{} X {}] distance matrix.".format(comp.shape[0], comp.shape[1]))
    else:
        logger.warning("Expression can be assessed vs connectivity or distance.")
        logger.warning("I don't understand '{}', and cannot continue.".format(args.comparator))
        sys.exit()
    return comp


def main():
    # Handle the many command-line arguments
    arguments = parse_args()

    logger = configure_logging(arguments)

    report_context(arguments, logger)

    # Instantiate and configure pygest
    data = ge.Data(arguments.ge_dir, logger)
    # for log_handler in logger.handlers:
    #     data.add_log_handler(log_handler)

    # Pull data from pygest stores
    expression = get_expression(data, arguments, logger)
    comparator = get_comparator(data, arguments, expression.columns, logger)

    # Execute the specified task
    if arguments.command.lower() == 'max_r':
        max_r(expression, comparator, arguments, logger)
    elif arguments.command.lower() == 'min_r':
        arguments.direction = 'min'
        max_r(expression, comparator, arguments, logger)
    elif arguments.command.lower() == 'order':
        order(expression, comparator, arguments, logger)
    elif arguments.command.lower() == 'make_null':
        make_null_dist(expression, comparator, arguments, logger)
    else:
        print("I don't recognize the command, '{}'".format(arguments.command))

    logger.info("Done")


if __name__ == '__main__':
    main()
